{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating\n",
      "0      196      242       3\n",
      "1      186      302       3\n",
      "2       22      377       1\n",
      "3      244       51       2\n",
      "4      166      346       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the u.data file\n",
    "file_path = '/Users/tarunvallabhaneni/MPCS Classes/Math of ML/Final Project/data/ml-100k/u.data'\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv(file_path, sep='\\t', names=column_names)\n",
    "ratings.drop('timestamp', axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(ratings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 943 entries, 1 to 943\n",
      "Columns: 1682 entries, 1 to 1682\n",
      "dtypes: float64(1682)\n",
      "memory usage: 12.1 MB\n",
      "None\n",
      "\n",
      "Sparsity of the matrix is 93.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# convert to matrix R\n",
    "user_item_matrix = ratings.pivot(index='user_id', columns='item_id', values='rating')\n",
    "\n",
    "user_item_matrix = user_item_matrix.fillna(0)\n",
    "\n",
    "# print info\n",
    "print(user_item_matrix.info())\n",
    "\n",
    "\n",
    "total_elements = user_item_matrix.shape[0] * user_item_matrix.shape[1]\n",
    "non_zero_elems = (user_item_matrix != 0).sum().sum()\n",
    "sparsity = 1 - (non_zero_elems / total_elements)\n",
    "print(f\"\\nSparsity of the matrix is {sparsity:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n",
      "(array([  0,   0,   0, ..., 942, 942, 942]), array([   0,    1,    2, ..., 1187, 1227, 1329]))\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "matrix_np = user_item_matrix.to_numpy()\n",
    "print(matrix_np)\n",
    "\n",
    "nonzero_indices = matrix_np.nonzero()\n",
    "nonzero_count = np.count_nonzero(matrix_np)\n",
    "print(nonzero_indices)\n",
    "print(nonzero_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class GD:\n",
    "    def __init__(self, R, k, learning_rate=0.001, reg_param=0.01, epochs=10, batch_size=100):\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.k = k\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg_param = reg_param  \n",
    "        self.num_epochs = epochs\n",
    "        self.rows, self.cols = self.R.nonzero()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # Calculate rating mean and std for normalization\n",
    "        self.rating_mean = np.mean(R[R.nonzero()])\n",
    "        self.rating_std = np.std(R[R.nonzero()])\n",
    "        \n",
    "        # Initialize \n",
    "        self.U = np.random.normal(0, 0.1, size=(self.num_users, self.k))\n",
    "        self.V = np.random.normal(0, 0.1, size=(self.num_items, self.k))\n",
    "        \n",
    "    def normalize_rating(self, rating):\n",
    "        \"\"\"Normalize rating to zero mean and unit variance\"\"\"\n",
    "        return (rating - self.rating_mean) / self.rating_std\n",
    "        \n",
    "    def denormalize_rating(self, normalized_rating):\n",
    "        \"\"\"Convert normalized rating back to original scale\"\"\"\n",
    "        return (normalized_rating * self.rating_std) + self.rating_mean\n",
    "\n",
    "\n",
    "    \n",
    "    def calculate_rmse(self, R):\n",
    "        \"\"\"Calculate RMSE\"\"\"\n",
    "        rows, cols = R.nonzero()\n",
    "        if len(rows) == 0:\n",
    "            return float('inf')\n",
    "            \n",
    "        r_true = R[rows, cols]\n",
    "        r_true_norm = self.normalize_rating(r_true)\n",
    "        r_pred = np.sum(self.U[rows] * self.V[cols], axis=1)\n",
    "        \n",
    "        errors = r_true_norm - r_pred\n",
    "        mse = np.mean(errors ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return mse, rmse\n",
    "\n",
    "        \n",
    "    def train(self, val_matrix=None):\n",
    "        indices = list(zip(self.rows, self.cols))\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "            for batch_start in range(0, len(indices), self.batch_size):\n",
    "                batch_indices = indices[batch_start:batch_start+self.batch_size]\n",
    "                \n",
    "                for i, j in batch_indices:\n",
    "                    r_true = self.R[i, j]\n",
    "                    r_true_norm = self.normalize_rating(r_true)\n",
    "                    r_pred = np.dot(self.U[i], self.V[j])  \n",
    "                    error = r_true_norm - r_pred\n",
    "                    \n",
    "                    # Gradient calculation\n",
    "                    u_grad = -2 * error * self.V[j] + 2 * self.reg_param * self.U[i]\n",
    "                    v_grad = -2 * error * self.U[i] + 2 * self.reg_param * self.V[j]\n",
    "                    \n",
    "                    \n",
    "                    # Update parameters\n",
    "                    self.U[i] -= self.learning_rate * u_grad\n",
    "                    self.V[j] -= self.learning_rate * v_grad\n",
    "            \n",
    "            # Calculate losses\n",
    "            _, rmse_train = self.calculate_rmse(self.R)\n",
    "            \n",
    "            \n",
    "            # Print progress\n",
    "            # if val_matrix is not None:\n",
    "            #     _, rmse_val = self.calculate_rmse(val_matrix)\n",
    "            #     print(f\"Epoch {epoch+1}/{self.num_epochs}, train RMSE: {rmse_train:.4f}, val RMSE: {rmse_val:.4f}\")\n",
    "            # else:\n",
    "            #     print(f\"Epoch {epoch+1}/{self.num_epochs}, train RMSE: {rmse_train:.4f}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_cross_validation(R, n_folds=5, test_size=0.2, random_state=42):\n",
    "    # Get observed (i, j) pairs from the matrix\n",
    "    rows, cols = R.nonzero()\n",
    "    data = list(zip(rows, cols))\n",
    "    \n",
    "    # Split data into train/val and test sets\n",
    "    train_val_data, test_data = train_test_split(data, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Create k folds\n",
    "    def k_folds(data, k):\n",
    "        np.random.shuffle(data)\n",
    "        fold_size = len(data) // k\n",
    "        leftover = len(data) % k\n",
    "        \n",
    "        folds = []\n",
    "        start = 0\n",
    "        for i in range(k):\n",
    "            extra = 1 if i < leftover else 0\n",
    "            end = start + fold_size + extra\n",
    "            folds.append(data[start:end])\n",
    "            start = end\n",
    "        return folds\n",
    "    \n",
    "    folds = k_folds(train_val_data, n_folds)\n",
    "    \n",
    "    # Create test matrix\n",
    "    test_matrix = np.zeros(R.shape)\n",
    "    for i, j in test_data:\n",
    "        test_matrix[i, j] = R[i, j]\n",
    "        \n",
    "    return folds, test_matrix\n",
    "\n",
    "def train_with_cross_validation(R, folds, model_params):\n",
    "    all_val_rmse = []\n",
    "    \n",
    "    for fold_idx, fold in enumerate(folds):\n",
    "        # print(f\"\\nTraining on fold {fold_idx + 1}\")\n",
    "        \n",
    "        # Prepare validation data\n",
    "        val_data = fold\n",
    "        train_data = [point for idx, f in enumerate(folds) if idx != fold_idx for point in f]\n",
    "        \n",
    "        # Create validation matrix\n",
    "        val_matrix = np.zeros(R.shape)\n",
    "        for i, j in val_data:\n",
    "            val_matrix[i, j] = R[i, j]\n",
    "            \n",
    "        # Create training matrix\n",
    "        train_matrix = np.zeros(R.shape)\n",
    "        for i, j in train_data:\n",
    "            train_matrix[i, j] = R[i, j]\n",
    "            \n",
    "        # Train model\n",
    "        model = GD(train_matrix, **model_params)\n",
    "        model.train(val_matrix)\n",
    "        \n",
    "        # Store validation RMSE\n",
    "        _, val_rmse = model.calculate_rmse(val_matrix)\n",
    "        all_val_rmse.append(val_rmse)\n",
    "        \n",
    "    # Compute average RMSE across all folds\n",
    "    average_val_rmse = np.mean(all_val_rmse)\n",
    "    # print(f\"\\nAverage Validation RMSE across all folds: {average_val_rmse:.4f}\")\n",
    "    \n",
    "    return average_val_rmse, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean validation loss across folds: 0.8538\n"
     ]
    }
   ],
   "source": [
    "folds, test_matrix = prepare_cross_validation(matrix_np, n_folds=5)\n",
    "model_params = {\n",
    "    'k': 30,\n",
    "    'learning_rate': 0.05,  \n",
    "    'reg_param': 0.1,       \n",
    "    'epochs': 20,\n",
    "    'batch_size': 100\n",
    "}\n",
    "mean_val_loss, final_model = train_with_cross_validation(matrix_np, folds, model_params)\n",
    "print(f\"\\nMean validation loss across folds: {mean_val_loss:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.7418\n",
      "Test RMSE: 0.8613\n"
     ]
    }
   ],
   "source": [
    "test_mse, test_rmse = final_model.calculate_rmse(test_matrix)\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "def hyperparameter_search(R, folds, hyperparams):\n",
    "    best_val_loss = float('inf')\n",
    "    best_hyperparams = None\n",
    "    \n",
    "    for param in hyperparams:\n",
    "        model_params = {\n",
    "            'k': param[0],\n",
    "            'learning_rate': param[1],\n",
    "            'reg_param': param[2],\n",
    "            'epochs': param[3],\n",
    "            'batch_size': 100\n",
    "        }\n",
    "\n",
    "        print(f\"\\nTraining with hyperparameter: {param}\")\n",
    "        \n",
    "        \n",
    "        val_loss, _ = train_with_cross_validation(R, folds, model_params)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_hyperparams = param\n",
    "            \n",
    "    return best_hyperparams, best_val_loss\n",
    "\n",
    "\n",
    "k_values = [10, 20, 30]\n",
    "learning_rates = [0.001, 0.005, 0.01]\n",
    "reg_params = [0.01, 0.05, 0.1]\n",
    "epochs = [10, 20, 30]\n",
    "\n",
    "hyperparam_combinations = list(itertools.product(k_values, learning_rates, reg_params, epochs))\n",
    "len(hyperparam_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.001, 0.1, 30)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.005, 0.1, 30)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (10, 0.01, 0.1, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.001, 0.1, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.005, 0.1, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (20, 0.01, 0.1, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.001, 0.1, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.005, 0.1, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.01, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.01, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.01, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.05, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.05, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.05, 30)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.1, 10)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.1, 20)\n",
      "\n",
      "Training with hyperparameter: (30, 0.01, 0.1, 30)\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams, best_val_loss = hyperparameter_search(matrix_np, folds, hyperparam_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 0.01, 0.1, 30), 0.8394406083907624)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
